{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From AIPC to the Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll train a CIFAR-10 image classification model using AI-powered computing (AIPC) and cloud resources. CIFAR-10 is a benchmark dataset with 60,000 images across 10 classes. Leveraging cloud infrastructure enables faster training and scalability.\n",
    "\n",
    "We'll cover dataset preprocessing, CNN model design, training with AIPC, and evaluation. This guide provides insights into optimizing model performance and deploying in production.\n",
    "\n",
    "Extracted from Pytorch example https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerations \n",
    "\n",
    "Training a model with a limited amount of data is a pragmatic approach, especially if you're in the early stages of model development or data collection. It allows you to quickly iterate and experiment with different model architectures, hyperparameters, and feature engineering techniques to identify what works best for your problem domain.\n",
    "\n",
    "Once you have a good understanding of what works and what doesn't, scaling up to a larger dataset can indeed be beneficial. More data often leads to better generalization and performance, as it helps the model learn more robust patterns and relationships within the data.\n",
    "\n",
    "However, there are a few considerations to keep in mind:\n",
    "\n",
    "- **Quality of Data**: Ensure that your limited dataset is representative of the broader population or distribution you're targeting. Biases or outliers in the limited dataset can skew the model's understanding and lead to poor generalization when scaling up.\n",
    "\n",
    "- **Overfitting**: With a limited dataset, there's a risk of overfitting—where the model learns to memorize the training data rather than generalize to unseen examples. Regularization techniques and validation strategies should be employed to mitigate this risk.\n",
    "\n",
    "- **Transferability**: Ideally, the insights gained from training on the limited dataset should transfer well to the larger dataset. However, there may be domain shifts or differences in data distribution between the two datasets, requiring careful adaptation and fine-tuning of the model.\n",
    "- **Computational Resources**: Training with a larger dataset typically requires more computational resources in terms of processing power, memory, and time. Ensure you have the necessary infrastructure to handle the increased scale.\n",
    "\n",
    "In summary, starting with a limited dataset for initial experimentation is a great approach, but it's essential to validate the model's performance on a larger dataset to ensure robustness and generalization. Additionally, continuous monitoring and refinement may be necessary as you scale up to address any new challenges or nuances introduced by the larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/ubuntu/.venv/lib/python3.10/site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/.venv/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ubuntu/.venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/ubuntu/.venv/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/ubuntu/.venv/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ubuntu/.venv/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pylibjpeg-libjpeg in /home/ubuntu/.venv/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.24 in /home/ubuntu/.venv/lib/python3.10/site-packages (from pylibjpeg-libjpeg) (1.26.4)\n",
      "Requirement already satisfied: libpng-bins in /home/ubuntu/.venv/lib/python3.10/site-packages (0.0.3)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.venv/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torchvision) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.3.0->torchvision) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.venv/lib/python3.10/site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install pylibjpeg-libjpeg\n",
    "!pip install libpng-bins\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and prepare data sets for AIPC and Cloud examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work with two versions of the CIFAR-10 dataset:\n",
    "\n",
    "1. **Short Dataset (for AI-powered computing)**:\n",
    "   This version comprises a subset of the CIFAR-10 dataset, containing a smaller number of images per class. It's designed for quick experimentation and testing on AI-powered computing resources.\n",
    "\n",
    "2. **Complete Dataset (for cloud computing)**:\n",
    "   The complete CIFAR-10 dataset consists of 60,000 images, evenly distributed across 10 classes. This version provides comprehensive training data and is suitable for training on cloud computing resources.\n",
    "\n",
    "By using these two datasets, we can efficiently utilize the resources available on both AI-powered computing and cloud platforms, ensuring rapid experimentation and robust model training.\n",
    "\n",
    "Let's load the datasets and proceed with our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_cloud/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:21<00:00, 8075351.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data_cloud/cifar-10-python.tar.gz to ./data_cloud\n",
      "Files already downloaded and verified\n",
      "Cloud Trainset size:  50000  images\n",
      "Cloud Testset size:  10000  images\n"
     ]
    }
   ],
   "source": [
    "### For Cloud we will use the entire Dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset_Cloud = torchvision.datasets.CIFAR10(root='./data_cloud', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader_Cloud = torch.utils.data.DataLoader(trainset_Cloud, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset_cloud = torchvision.datasets.CIFAR10(root='./data_cloud', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader_cloud = torch.utils.data.DataLoader(testset_cloud, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Display each dataset size\n",
    "print(\"Cloud Trainset size: \", len(trainset_Cloud),\" images\")\n",
    "print(\"Cloud Testset size: \", len(testset_cloud),\" images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_ai_pc/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:07<00:00, 21479633.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data_ai_pc/cifar-10-python.tar.gz to ./data_ai_pc\n",
      "Number of samples in trainset_AI_PC: 5000\n",
      "Number of samples in testset_AI_PC: 2000\n"
     ]
    }
   ],
   "source": [
    "## For AI PC we will use a portion (40%  20,000) of the initial dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Initialize the CIFAR-10 dataset and download it\n",
    "full_dataset = torchvision.datasets.CIFAR10(root='./data_ai_pc', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "\n",
    "# Size of the first subset\n",
    "train_size_AI_PC = 5000\n",
    "\n",
    "# Get the labels for each sample in the full dataset\n",
    "labels = torch.tensor(full_dataset.targets)\n",
    "\n",
    "# Use stratified sampling to split the dataset into train and test sets\n",
    "train_indices, test_indices = train_test_split(range(len(full_dataset)), train_size=train_size_AI_PC,test_size=2000,\n",
    "                                               stratify=labels, random_state=42)\n",
    "\n",
    "# Create the train and test subsets using the selected indices\n",
    "trainset_AI_PC = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "testset_AI_PC = torch.utils.data.Subset(full_dataset, test_indices)\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 4\n",
    "trainloader_AI_PC = torch.utils.data.DataLoader(trainset_AI_PC, batch_size=batch_size, shuffle=True)\n",
    "testloader_AI_PC = torch.utils.data.DataLoader(testset_AI_PC, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print the number of samples in each subset\n",
    "print(\"Number of samples in trainset_AI_PC:\", len(trainset_AI_PC))\n",
    "print(\"Number of samples in testset_AI_PC:\", len(testset_AI_PC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car   car   horse horse\n"
     ]
    }
   ],
   "source": [
    "# Display dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader_AI_PC)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.  Define Neural Network and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, we define a convolutional neural network (CNN) model using PyTorch. Below is a breakdown of the model definition:\n",
    "\n",
    "1. **Module Definition**: The model is defined as a subclass of `nn.Module`, the base class for all neural network modules in PyTorch.\n",
    "\n",
    "2. **Initialization Method (`__init__`)**:\n",
    "   - The `__init__` method initializes the neural network layers, including convolutional layers, max-pooling layers, and fully connected layers.\n",
    "   - It sets up the architecture of the model, comprising two convolutional layers (`conv1` and `conv2`), two max-pooling layers (`pool`), and three fully connected layers (`fc1`, `fc2`, and `fc3`).\n",
    "\n",
    "3. **Forward Method (`forward`)**:\n",
    "   - The `forward` method defines the forward pass of the network, specifying how input data flows through the layers to produce the output.\n",
    "   - It applies convolutional operations, ReLU activation functions, max-pooling, and flattening to transform the input data.\n",
    "   - Finally, it computes the output of the neural network.\n",
    "   \n",
    "This model architecture is a common design for image classification tasks, leveraging convolutional layers to extract features from input images and fully connected layers for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training and Testing on XPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will train and test our CIFAR-10 model, named `model_ipex_XXXX` (_aipc/cloud) \n",
    "\n",
    "### Training Process\n",
    "1. **Data Loading**: We'll load the training dataset and set up data loaders to provide batches of images and labels to the model during training.\n",
    "2. **Model Initialization**: Initialize an instance of our neural network model `model_ipex_XXX`.\n",
    "3. **Optimizer Configuration**: We'll set up an optimizer for training. In this case, we'll use the `ipex.optimize` function provided by IPEX to optimize our model, utilizing the `torch.bfloat16` data type.\n",
    "4. **Training Loop**: Iterate over the training dataset, passing batches of data through the model, computing gradients, and updating model parameters to minimize the loss.\n",
    "5. **Monitoring Progress**: Monitor training metrics such as loss and accuracy to assess the model's performance during training.\n",
    "\n",
    "### Testing Process\n",
    "1. **Data Loading**: Load the testing dataset to evaluate the trained model's performance.\n",
    "2. **Model Evaluation**: Pass testing data through the trained model and compute predictions.\n",
    "3. **Performance Metrics**: Calculate performance metrics such as accuracy to evaluate the model's performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 AI PC \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Training \n",
    "The NN will be trained using intel IPEX for aditional optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intel_extension_for_pytorch as ipex\n",
    "import torch.optim as optim\n",
    "\n",
    "model_ipex_aipc = Net()\n",
    "\n",
    "#Convert model to run on GPU\n",
    "model_ipex_aipc = model_ipex_aipc.to('xpu')\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ipex_aipc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Invoke optimize function against the model object and optimizer object\n",
    "model_ipex_aipc, optimizer = ipex.optimize(model_ipex_aipc, optimizer=optimizer, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate execution time\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader_AI_PC, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        #Convert Data Set to run on GPU\n",
    "        inputs = inputs.to('xpu',dtype=torch.bfloat16)\n",
    "        labels = labels.to('xpu')\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model_ipex_aipc(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 700 == 699:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "#calculate execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f'Execution time: {execution_time} seconds')\n",
    "print(f'Length of the dataset: {len(trainset_AI_PC)}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "start_time = time.time()\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader_AI_PC:\n",
    "        images, labels = data\n",
    "\n",
    "        # Convert to run on GPU\n",
    "        images = images.to('xpu',dtype=torch.bfloat16)\n",
    "        labels = labels.to('xpu')\n",
    "        outputs = model_ipex_aipc(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        # collect the correct predictions for each class and convert to XPU bfloat 16\n",
    "        predictions = predictions.to('xpu',dtype=torch.bfloat16)\n",
    "\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "#calculate execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f'Execution time: {execution_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intel_extension_for_pytorch as ipex\n",
    "import torch.optim as optim\n",
    "\n",
    "model_ipex_cloud = Net()\n",
    "\n",
    "#Convert model to run on GPU\n",
    "model_ipex_cloud = model_ipex_cloud.to('xpu')\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ipex_cloud.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Invoke optimize function against the model object and optimizer object\n",
    "model_ipex_cloud, optimizer = ipex.optimize(model_ipex_cloud, optimizer=optimizer, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate execution time\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader_Cloud, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        #Convert Data Set to run on GPU\n",
    "        inputs = inputs.to('xpu',dtype=torch.bfloat16)\n",
    "        labels = labels.to('xpu')\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model_ipex_cloud(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 700 == 699:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "            \n",
    "#calculate execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f'Execution time: {execution_time} seconds')\n",
    "print(f'Length of the dataset: {len(trainset_AI_PC)}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "start_time = time.time()\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader_cloud:\n",
    "        images, labels = data\n",
    "\n",
    "        # Convert to run on GPU\n",
    "        images = images.to('xpu',dtype=torch.bfloat16)\n",
    "        labels = labels.to('xpu')\n",
    "        outputs = model_ipex_cloud(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        # collect the correct predictions for each class\n",
    "        predictions = predictions.to('xpu',dtype=torch.bfloat16)\n",
    "\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "# print accuracy for each class            \n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "#calculate execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f'Execution time: {execution_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Training and testing on CPU only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will train and test our CIFAR-10 model, named `model_ipex_XXXX` (_aipc/cloud) \n",
    "\n",
    "### Training Process\n",
    "1. **Data Loading**: We'll load the training dataset and set up data loaders to provide batches of images and labels to the model during training.\n",
    "2. **Model Initialization**: Initialize an instance of our neural network model `model_ipex_XXX`.\n",
    "3. **Optimizer Configuration**: We'll set up an optimizer for training. In this case, we'll use the `ipex.optimize` function provided by IPEX to optimize our model, utilizing the `torch.bfloat16` data type.\n",
    "4. **Training Loop**: Iterate over the training dataset, passing batches of data through the model, computing gradients, and updating model parameters to minimize the loss.\n",
    "5. **Monitoring Progress**: Monitor training metrics such as loss and accuracy to assess the model's performance during training.\n",
    "\n",
    "### Testing Process\n",
    "1. **Data Loading**: Load the testing dataset to evaluate the trained model's performance.\n",
    "2. **Model Evaluation**: Pass testing data through the trained model and compute predictions.\n",
    "3. **Performance Metrics**: Calculate performance metrics such as accuracy to evaluate the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\n",
      "Collecting torch==2.2.0+cpu\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torch-2.2.0%2Bcpu-cp310-cp310-linux_x86_64.whl (186.7 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchvision-0.18.0%2Bcpu-cp310-cp310-linux_x86_64.whl (1.6 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.3.0%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.2.0+cpu) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.2.0+cpu) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.2.0+cpu) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.2.0+cpu) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.2.0+cpu) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.venv/lib/python3.10/site-packages (from torch==2.2.0+cpu) (2024.3.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.venv/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.17.2%2Bcpu-cp310-cp310-linux_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.17.1%2Bcpu-cp310-cp310-linux_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.17.0%2Bcpu-cp310-cp310-linux_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ubuntu/.venv/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.2.2%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.2.1%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading torchaudio-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.2.0%2Bcpu-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from jinja2->torch==2.2.0+cpu) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.venv/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.venv/lib/python3.10/site-packages (from requests->torchvision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.venv/lib/python3.10/site-packages (from requests->torchvision) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.venv/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.venv/lib/python3.10/site-packages (from sympy->torch==2.2.0+cpu) (1.3.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.2.0+cpu torchaudio-2.2.0+cpu torchvision-0.17.0+cpu\n",
      "Requirement already satisfied: intel-extension-for-pytorch in /home/ubuntu/.venv/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.venv/lib/python3.10/site-packages (from intel-extension-for-pytorch) (5.9.8)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.venv/lib/python3.10/site-packages (from intel-extension-for-pytorch) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.venv/lib/python3.10/site-packages (from intel-extension-for-pytorch) (23.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pytorch-extension.intel.com/release-whl/stable/cpu/us/\n",
      "Requirement already satisfied: oneccl_bind_pt in /home/ubuntu/.venv/lib/python3.10/site-packages (2.2.0+cpu)\n"
     ]
    }
   ],
   "source": [
    "# instalation of IPEX for CPU only according to https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=cpu&version=v2.2.0%2bcpu&os=linux%2fwsl2&package=pip\n",
    "\n",
    "# Uninstall actual version of pytorch\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "# install version 2.2.0 of pytorch and IPEX\n",
    "!pip install torch==2.2.0+cpu torchvision torchaudio -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "!pip install intel-extension-for-pytorch\n",
    "!pip install oneccl_bind_pt --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/cpu/us/\n",
    "\n",
    "# DON'T FORGET TO RESTART THE KERNEL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 AI PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NN will be trained using intel IPEX for aditional optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intel_extension_for_pytorch as ipex\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "model_ipex_aipc = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ipex_aipc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Invoke optimize function against the model object and optimizer object\n",
    "model_ipex_aipc, optimizer = ipex.optimize(model_ipex_aipc, optimizer=optimizer, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   700] loss: 0.806\n",
      "[2,   700] loss: 0.718\n",
      "Execution time: 7.9886462688446045 seconds\n",
      "Length of the dataset: 5000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Calculate execution time\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader_AI_PC, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Train on CPU\n",
    "        with torch.cpu.amp.autocast():\n",
    "            output = model_ipex_aipc(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 700 == 699:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "#calculate execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f'Execution time: {execution_time} seconds')\n",
    "print(f'Length of the dataset: {len(trainset_AI_PC)}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 72.0 %\n",
      "Accuracy for class: car   is 16.5 %\n",
      "Accuracy for class: bird  is 6.0 %\n",
      "Accuracy for class: cat   is 5.5 %\n",
      "Accuracy for class: deer  is 22.5 %\n",
      "Accuracy for class: dog   is 30.5 %\n",
      "Accuracy for class: frog  is 53.0 %\n",
      "Accuracy for class: horse is 38.0 %\n",
      "Accuracy for class: ship  is 27.5 %\n",
      "Accuracy for class: truck is 27.5 %\n",
      "Execution time: 0.4601593017578125 seconds\n"
     ]
    }
   ],
   "source": [
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "model_ipex_aipc.eval() \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader_AI_PC:\n",
    "        images, labels = data\n",
    "        with torch.cpu.amp.autocast():\n",
    "            outputs = model_ipex_aipc(images)\n",
    "            _, predictions = torch.max(outputs, 1)  # Get predicted labels\n",
    "\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction.item():  # Convert prediction to Python scalar\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "# calculate execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f'Execution time: {execution_time} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intel_extension_for_pytorch as ipex\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "model_ipex_cloud = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ipex_cloud.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Invoke optimize function against the model object and optimizer object\n",
    "model_ipex_cloud, optimizer = ipex.optimize(model_ipex_cloud, optimizer=optimizer, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.240\n",
      "[1,  4000] loss: 1.923\n",
      "[1,  6000] loss: 1.677\n",
      "[1,  8000] loss: 1.579\n",
      "[1, 10000] loss: 1.482\n",
      "[1, 12000] loss: 1.462\n",
      "[2,  2000] loss: 1.394\n",
      "[2,  4000] loss: 1.382\n",
      "[2,  6000] loss: 1.324\n",
      "[2,  8000] loss: 1.328\n",
      "[2, 10000] loss: 1.323\n",
      "[2, 12000] loss: 1.325\n",
      "Execution time: 79.64300084114075 seconds\n",
      "Length of the dataset: 50000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Calculate execution time\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader_Cloud, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        # Train on CPU\n",
    "        with torch.cpu.amp.autocast():\n",
    "            output = model_ipex_cloud(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "       \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "#calculate execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f'Execution time: {execution_time} seconds')\n",
    "print(f'Length of the dataset: {len(trainset_Cloud)}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 69.5 %\n",
      "Accuracy for class: car   is 73.3 %\n",
      "Accuracy for class: bird  is 23.6 %\n",
      "Accuracy for class: cat   is 15.7 %\n",
      "Accuracy for class: deer  is 39.9 %\n",
      "Accuracy for class: dog   is 64.0 %\n",
      "Accuracy for class: frog  is 66.0 %\n",
      "Accuracy for class: horse is 71.5 %\n",
      "Accuracy for class: ship  is 55.7 %\n",
      "Accuracy for class: truck is 59.9 %\n",
      "Execution time: 2.2864999771118164 seconds\n"
     ]
    }
   ],
   "source": [
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "model_ipex_cloud.eval() \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader_cloud:\n",
    "        images, labels = data\n",
    "        with torch.cpu.amp.autocast():\n",
    "            outputs = model_ipex_cloud(images)\n",
    "            _, predictions = torch.max(outputs, 1)  # Get predicted labels\n",
    "\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction.item():  # Convert prediction to Python scalar\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "# calculate execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f'Execution time: {execution_time} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
